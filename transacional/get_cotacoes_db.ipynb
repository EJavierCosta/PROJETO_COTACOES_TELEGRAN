{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a1c54d-2272-4bd8-85e0-d71aae5facf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, ArrayType, LongType\n",
    "from pyspark.sql.functions import col, explode, from_unixtime, to_date, to_timestamp\n",
    "import delta\n",
    "\n",
    "token = dbutils.secrets.get(scope=\"meu-escopo\", key=\"token_brapi\")\n",
    "tickers = [\"ABCB4\",\"UNIP6\", \"PETR4\", \"VALE3\", \"ITUB4\", \"BBAS3\", \"BBDC4\", \"ITSA4\", \"RANI3\", \"EGIE3\", \"PRIO3\",\"BRAV3\",\"JHSF3\",\"BBSE3\"]\n",
    "#\"UNIP6\", \"PETR4\", \"VALE3\", \"ITUB4\", \"BBAS3\", \"BBDC4\", \"ITSA4\", \"RANI3\", \"EGIE3\", \"PRIO3\",\"BRAV3\",\"JHSF3\",\"BBSE3\"\n",
    "schema_historico = StructType([StructField(\"date\", StringType(), True),\n",
    "                               StructField(\"open\", DoubleType(), True),\n",
    "                               StructField(\"high\", DoubleType(), True),\n",
    "                               StructField(\"low\", DoubleType(), True),\n",
    "                               StructField(\"close\", DoubleType(), True),\n",
    "                               StructField(\"volume\",LongType(), True)                            \n",
    "                               ])\n",
    "schema = StructType([StructField(\"Simbolo\", StringType(), False),\n",
    "                     StructField(\"Nome\", StringType(), True),\n",
    "                     StructField(\"Moeda\", StringType(), True),\n",
    "                     StructField(\"Cotacao\", DoubleType(), True),\n",
    "                     StructField(\"Intervalo_52_Semanas\", StringType(), True),\n",
    "                     StructField(\"Data\", StringType(), True),\n",
    "                     StructField(\"Historico_cotacao\", ArrayType(schema_historico), True)\n",
    "                     ])\n",
    "\n",
    "for ticker in tickers:\n",
    "    #api brabi\n",
    "    url = f\"https://brapi.dev/api/quote/{ticker}?token={token}\"\n",
    "   \n",
    "    response = requests.get(url,params={\"range\": \"3mo\", \"interval\": \"1d\"})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        dados_brapi = response.json()[\"results\"][0]\n",
    "   \n",
    "        # Cria o DataFrame Spark\n",
    "        data = [(dados_brapi[\"symbol\"],\n",
    "                dados_brapi[\"shortName\"],\n",
    "                dados_brapi[\"currency\"],\n",
    "                dados_brapi[\"regularMarketPrice\"],\n",
    "                dados_brapi[\"fiftyTwoWeekRange\"],\n",
    "                dados_brapi[\"regularMarketTime\"],\n",
    "                dados_brapi[\"historicalDataPrice\"])]\n",
    "\n",
    "        df_temp = spark.createDataFrame(data, schema)\n",
    "        df_spark = df_temp.withColumn(\"Data\", to_timestamp(col(\"Data\"))).drop(\"Historico_cotacao\")\n",
    "        df_spark_hist = df_temp.select(col(\"Simbolo\"),(explode(col(\"Historico_cotacao\")).alias(\"Historico\"))).select(\"Simbolo\",\"Historico.*\")\n",
    "        df_spark_hist = df_spark_hist.withColumn(\"date\", to_date(from_unixtime(col(\"date\"))))\n",
    "\n",
    "        if spark.catalog.tableExists(\"transacional.cotacoes_db.cotacoes\"):\n",
    "\n",
    "            transacional_cotacoes = delta.DeltaTable.forName(spark, \"transacional.cotacoes_db.cotacoes\")\n",
    "            \n",
    "            (transacional_cotacoes.alias(\"r\")\n",
    "                                  .merge(df_spark.alias(\"s\"),\"r.Simbolo = s.Simbolo\")\n",
    "                                  .whenMatchedUpdateAll() # Se encontrar o Simbolo, atualiza todas as colunas\n",
    "                                  .whenNotMatchedInsertAll() # Se n√£o encontrar, insere a nova linha\n",
    "                                  .execute()\n",
    "                                  )\n",
    "            print(f\"adicionado dados de {ticker} na tabela cotacoes\")\n",
    "        else:\n",
    "            (df_spark.writeTo(\"transacional.cotacoes_db.cotacoes\")\n",
    "                     .tableProperty(\"delta.autoOptimize.optimizeWrite\", \"true\")\n",
    "                     .tableProperty(\"delta.autoOptimize.autoCompact\", \"true\")\n",
    "                     .tableProperty(\"delta.enableChangeDataFeed\", \"true\")\n",
    "                     .using(\"delta\")\n",
    "                     .create()\n",
    "                     )\n",
    "            print(\"criando tabela cotacoes\")\n",
    "        if spark.catalog.tableExists(\"transacional.cotacoes_db.hist_cotacoes\"):\n",
    "            delta_table_hist = delta.DeltaTable.forName(spark, \"transacional.cotacoes_db.hist_cotacoes\")\n",
    "            (delta_table_hist.alias(\"a\")\n",
    "                             .merge(df_spark_hist.alias(\"b\"), \"a.simbolo = b.simbolo AND a.date = b.date\")                        \n",
    "                             .whenNotMatchedInsertAll() \n",
    "                             .execute()\n",
    "                             ) \n",
    "            print(f\"adicionado dados de {ticker} na tabela hist_cotacoes\")                \n",
    "        else:\n",
    "            (df_spark_hist.writeTo(\"transacional.cotacoes_db.hist_cotacoes\")\n",
    "                        .tableProperty(\"delta.autoOptimize.optimizeWrite\", \"true\")\n",
    "                        .tableProperty(\"delta.autoOptimize.autoCompact\", \"true\")\n",
    "                        .tableProperty(\"delta.enableChangeDataFeed\", \"true\")\n",
    "                        .using(\"delta\")\n",
    "                        .create()\n",
    "                        )\n",
    "            print(\"criando tabela hist_cotacoes\")\n",
    "        \n",
    "        #print(f\"Coleta realizada com sucesso, status code: {response.status_code}\")\n",
    "        #display(df_spark)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Erro: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "get_cotacoes_db",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
