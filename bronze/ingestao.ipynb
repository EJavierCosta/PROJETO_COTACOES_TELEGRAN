{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe892c8d-b131-403f-8491-6366463a811d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "IMPORTS"
    }
   },
   "outputs": [],
   "source": [
    "import delta\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b5d9700-f5b7-487e-92a3-e8a2025c2d12",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SETUP"
    }
   },
   "outputs": [],
   "source": [
    "# tabela = dbutils.widgets.get(\"tabela\")\n",
    "tabela =\"cotacoes\"\n",
    "schema = \"cotacoes_bronze\"\n",
    "catalog = \"prod\"\n",
    "checkpointpath = f\"/Volumes/transacional/cotacoes_db/checkpoint/checkpoint_{tabela}\"\n",
    "dbpath = f\"transacional.cotacoes_db.{tabela}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f593b9f-fa32-4077-961a-8b26e109a28f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ingestao:\n",
    "    def __init__(self, tabela, schema, catalog, dbpath):\n",
    "        self.tabela = tabela\n",
    "        self.schema = schema\n",
    "        self.catalog = catalog\n",
    "        self.dbpath = dbpath\n",
    "        \n",
    "\n",
    "    def carga(self):\n",
    "        db = (spark.read\n",
    "                        .format(\"delta\")\n",
    "                        .table(self.dbpath)\n",
    "                        )   \n",
    "        return db\n",
    "    \n",
    "    def salva(self, db):\n",
    "        (db.writeTo(f\"{self.catalog}.{self.schema}.{self.tabela}\")\n",
    "           .tableProperty(\"delta.autoOptimize.optimizeWrite\", \"true\")\n",
    "           .tableProperty(\"delta.autoOptimize.autoCompact\", \"true\")\n",
    "           .tableProperty(\"delta.enableChangeDataFeed\", \"true\")\n",
    "           .using(\"delta\")\n",
    "           .createOrReplace()\n",
    "           )  \n",
    "        return True\n",
    "    \n",
    "    def run(self):\n",
    "        db = self.carga()\n",
    "        return self.salva(db)\n",
    "    \n",
    "class ingestaoCDC (ingestao):\n",
    "    def __init__(self, tabela, schema, catalog, dbpath, checkpointpath):\n",
    "        super().__init__(tabela, schema, catalog, dbpath)\n",
    "        self.checkpointpath = checkpointpath\n",
    "        \n",
    "\n",
    "    def settabela (self):\n",
    "        bronze = delta.DeltaTable.forName(spark, f\"{self.catalog}.{self.schema}.{self.tabela}\")\n",
    "        return bronze\n",
    "\n",
    "    def upsert (self, df, bronze):\n",
    "        # Filtra os tipos de mudança que não interessam\n",
    "        df_filtered = df.filter(col(\"_change_type\") != 'update_preimage')\n",
    "\n",
    "        # Define o registro mais recente por Símbolo\n",
    "        windowSpec = Window.partitionBy(\"Simbolo\").orderBy(desc(\"_commit_timestamp\"), desc(\"_commit_version\"))\n",
    "\n",
    "        # Pega a última atualização para cada Símbolo\n",
    "        df_cotacoes_cdc = (df_filtered.withColumn(\"row_num\", row_number().over(windowSpec))\n",
    "                                        .filter(col(\"row_num\") == 1)\n",
    "                                        .drop(\"row_num\"))\n",
    "\n",
    "        (bronze.alias(\"b\")\n",
    "             .merge(df_cotacoes_cdc.alias(\"c\"),\"b.Simbolo = c.Simbolo\")\n",
    "             .whenMatchedDelete(condition = \"c._change_type = 'delete'\")\n",
    "             .whenMatchedUpdateAll(condition = \"c._change_type = 'update_postimage'\")\n",
    "             .whenNotMatchedInsertAll(condition = \"c._change_type = 'insert' OR c._change_type = 'update_postimage'\")  \n",
    "             .execute()\n",
    "             )\n",
    "\n",
    "    def leituraCDC (self):\n",
    "        tabela_cdc= (spark.readStream\n",
    "                               .format(\"delta\")\n",
    "                               .option(\"readChangeFeed\", \"true\")\n",
    "                               .option(\"startingVersion\", 0)  \n",
    "                               .table(self.dbpath)\n",
    "                               )\n",
    "        return tabela_cdc\n",
    "        \n",
    "    def salvaCDC (self, tabela_cdc, bronze):\n",
    "        stream = (tabela_cdc.writeStream\n",
    "                      .trigger(availableNow=True)\n",
    "                      .option(\"checkpointLocation\", self.checkpointpath)\n",
    "                      .foreachBatch(lambda df, batchId: self.upsert(df, bronze))\n",
    "                      )\n",
    "        return stream.start()\n",
    "    \n",
    "    def runCDC (self):\n",
    "        bronze = self.settabela()\n",
    "        tabela_cdc = self.leituraCDC()\n",
    "        return self.salvaCDC(tabela_cdc, bronze)\n",
    "\n",
    "    \n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fc5a69d-9532-409e-9ebf-58668933fe67",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "INGESTÃO FULL LOAD"
    }
   },
   "outputs": [],
   "source": [
    "if not spark.catalog.tableExists(f\"{catalog}.{schema}.{tabela}\"):\n",
    "\n",
    "        print(\"Tabela não existente, criando.\")\n",
    "        dbutils.fs.rm(checkpointpath, recurse=True)  \n",
    "        ingestao_full_load = ingestao(tabela, schema, catalog, dbpath)\n",
    "        \n",
    "        if ingestao_full_load.run():\n",
    "                print(\"Tabela criada com sucesso!\")\n",
    "        else:\n",
    "                print(\"Falha ao criar tabela!\")\n",
    "\n",
    "else:\n",
    "        print(\"Tabela já existente, ignorando FULL LOAD\")\n",
    "\n",
    "ingestao_cdc = ingestaoCDC(tabela, schema, catalog, dbpath, checkpointpath)\n",
    "ingestao_cdc.runCDC()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7901972089961355,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ingestao",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
